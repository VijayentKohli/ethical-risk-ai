{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pickle\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas version: 2.2.2\n",
      "scikit-learn version: 1.4.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "print(f'pandas version: {pd.__version__}')\n",
    "print(f'scikit-learn version: {sklearn.__version__}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_path = 'data_new.csv'\n",
    "df = pd.read_csv(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle age bands to create a consolidated 'age' feature\n",
    "age_band_columns = [\n",
    "    'dem_age_band_18-24_tm1', 'dem_age_band_25-34_tm1', 'dem_age_band_35-44_tm1',\n",
    "    'dem_age_band_45-54_tm1', 'dem_age_band_55-64_tm1', 'dem_age_band_65-74_tm1', 'dem_age_band_75+_tm1'\n",
    "]\n",
    "\n",
    "# Check if age band columns exist\n",
    "if any(col in df.columns for col in age_band_columns):\n",
    "    # Create a numerical 'age' feature based on age bands\n",
    "    age_mapping = {\n",
    "        'dem_age_band_18-24_tm1': 21,\n",
    "        'dem_age_band_25-34_tm1': 30,\n",
    "        'dem_age_band_35-44_tm1': 40,\n",
    "        'dem_age_band_45-54_tm1': 50,\n",
    "        'dem_age_band_55-64_tm1': 60,\n",
    "        'dem_age_band_65-74_tm1': 70,\n",
    "        'dem_age_band_75+_tm1': 80\n",
    "    }\n",
    "    df['age'] = sum(df[band] * age_mapping[band] for band in age_band_columns if band in df.columns)\n",
    "else:\n",
    "    print(\"No age bands found in the dataset.\")\n",
    "\n",
    "# Handle missing values by filling with median for numeric columns\n",
    "df.fillna(df.median(numeric_only=True), inplace=True)\n",
    "\n",
    "# Encode the categorical variable 'race' if it is non-numeric\n",
    "if 'race' in df.columns and df['race'].dtype == 'object':\n",
    "    df['race'] = LabelEncoder().fit_transform(df['race'])\n",
    "\n",
    "# Consolidate \"biomarkers\" into a single column\n",
    "biomarker_columns = [\n",
    "    'cre_min-low_tm1', 'cre_min-high_tm1', 'cre_min-normal_tm1',\n",
    "    'cre_mean-low_tm1', 'cre_mean-high_tm1', 'cre_mean-normal_tm1',\n",
    "    'cre_max-low_tm1', 'cre_max-high_tm1', 'cre_max-normal_tm1',\n",
    "    'crp_min-low_tm1', 'crp_min-high_tm1', 'crp_min-normal_tm1',\n",
    "    'crp_mean-low_tm1', 'crp_mean-high_tm1', 'crp_mean-normal_tm1',\n",
    "    'crp_max-low_tm1', 'crp_max-high_tm1', 'crp_max-normal_tm1',\n",
    "    'esr_min-low_tm1', 'esr_min-high_tm1', 'esr_min-normal_tm1',\n",
    "    'esr_mean-low_tm1', 'esr_mean-high_tm1', 'esr_mean-normal_tm1',\n",
    "    'esr_max-low_tm1', 'esr_max-high_tm1', 'esr_max-normal_tm1',\n",
    "    'ghba1c_min-low_tm1', 'ghba1c_min-high_tm1', 'ghba1c_min-normal_tm1',\n",
    "    'ghba1c_mean-low_tm1', 'ghba1c_mean-high_tm1', 'ghba1c_mean-normal_tm1',\n",
    "    'ghba1c_max-low_tm1', 'ghba1c_max-high_tm1', 'ghba1c_max-normal_tm1',\n",
    "    'hct_min-low_tm1', 'hct_min-high_tm1', 'hct_min-normal_tm1',\n",
    "    'hct_mean-low_tm1', 'hct_mean-high_tm1', 'hct_mean-normal_tm1',\n",
    "    'hct_max-low_tm1', 'hct_max-high_tm1', 'hct_max-normal_tm1',\n",
    "    'ldl_min-low_tm1', 'ldl_min-high_tm1', 'ldl_min-normal_tm1',\n",
    "    'ldl-mean-low_tm1', 'ldl-mean-high_tm1', 'ldl-mean-normal_tm1',\n",
    "    'ldl_max-low_tm1', 'ldl_max-high_tm1', 'ldl_max-normal_tm1',\n",
    "    'nt_bnp_min-low_tm1', 'nt_bnp_min-high_tm1', 'nt_bnp_min-normal_tm1',\n",
    "    'nt_bnp_mean-low_tm1', 'nt_bnp_mean-high_tm1', 'nt_bnp_mean-normal_tm1',\n",
    "    'nt_bnp_max-low_tm1', 'nt_bnp_max-high_tm1', 'nt_bnp_max-normal_tm1',\n",
    "    'sodium_min-low_tm1', 'sodium_min-high_tm1', 'sodium_min-normal_tm1',\n",
    "    'sodium_mean-low_tm1', 'sodium_mean-high_tm1', 'sodium_mean-normal_tm1',\n",
    "    'sodium_max-low_tm1', 'sodium_max-high_tm1', 'sodium_max-normal_tm1',\n",
    "    'trig_min-low_tm1', 'trig_min-high_tm1', 'trig_min-normal_tm1',\n",
    "    'trig_mean-low_tm1', 'trig_mean-high_tm1', 'trig_mean-normal_tm1',\n",
    "    'trig_max-low_tm1', 'trig_max-high_tm1', 'trig_max-normal_tm1'\n",
    "]\n",
    "\n",
    "# Create the \"biomarkers\" feature by checking if any values indicate \"normal\"\n",
    "if all(col in df.columns for col in biomarker_columns):\n",
    "    df['biomarkers'] = df[biomarker_columns].apply(lambda row: 1 if any('normal' in col and row[col] > 0 for col in biomarker_columns) else 0, axis=1)\n",
    "else:\n",
    "    print(\"Some biomarker columns are missing from the dataset.\")\n",
    "\n",
    "# Consolidate \"comorbidity\" into a single column\n",
    "comorbidity_columns = [\n",
    "    'alcohol_elixhauser_tm1', 'anemia_elixhauser_tm1', 'arrhythmia_elixhauser_tm1',\n",
    "    'arthritis_elixhauser_tm1', 'bloodlossanemia_elixhauser_tm1', 'coagulopathy_elixhauser_tm1',\n",
    "    'compdiabetes_elixhauser_tm1', 'depression_elixhauser_tm1', 'drugabuse_elixhauser_tm1',\n",
    "    'electrolytes_elixhauser_tm1', 'hypertension_elixhauser_tm1', 'hypothyroid_elixhauser_tm1',\n",
    "    'liver_elixhauser_tm1', 'neurodegen_elixhauser_tm1', 'obesity_elixhauser_tm1',\n",
    "    'paralysis_elixhauser_tm1', 'psychosis_elixhauser_tm1', 'pulmcirc_elixhauser_tm1',\n",
    "    'pvd_elixhauser_tm1', 'renal_elixhauser_tm1', 'uncompdiabetes_elixhauser_tm1',\n",
    "    'valvulardz_elixhauser_tm1', 'wtloss_elixhauser_tm1', 'cerebrovasculardz_romano_tm1',\n",
    "    'chf_romano_tm1', 'dementia_romano_tm1', 'hemiplegia_romano_tm1', 'hivaids_romano_tm1',\n",
    "    'metastatic_romano_tm1', 'myocardialinfarct_romano_tm1', 'pulmonarydz_romano_tm1',\n",
    "    'tumor_romano_tm1', 'ulcer_romano_tm1'\n",
    "]\n",
    "\n",
    "# Create the \"comorbidity\" feature by summing the relevant columns if columns are available\n",
    "if all(col in df.columns for col in comorbidity_columns):\n",
    "    df['comorbidity'] = df[comorbidity_columns].sum(axis=1)\n",
    "else:\n",
    "    print(\"Some comorbidity columns are missing from the dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the features to be used for model training\n",
    "features = ['cost_t', 'age', 'dem_female', 'race', 'biomarkers', 'comorbidity']\n",
    "\n",
    "# Check that all features are available in the dataset\n",
    "missing_features = [feature for feature in features if feature not in df.columns]\n",
    "if missing_features:\n",
    "    print(f\"Missing features from the dataset: {missing_features}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 15.702192304246264\n",
      "R-squared: 0.4454525483955426\n",
      "       Feature  Importance\n",
      "0       cost_t    0.412919\n",
      "1          age    0.088728\n",
      "2   dem_female    0.030780\n",
      "3         race    0.024531\n",
      "4   biomarkers    0.024343\n",
      "5  comorbidity    0.418699\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Proceed only if no features are missing\n",
    "if not missing_features:\n",
    "    # Prepare the features (X) and target (y)\n",
    "    X = df[features]\n",
    "    y = df['risk_score_t']\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Save the scaler in binary\n",
    "    with open('standard_scaler.pkl', 'wb') as scaler_file_out:\n",
    "        pickle.dump(scaler, scaler_file_out)\n",
    "\n",
    "# Save the scaler in binary\n",
    "    with open('standard_scaler.pkl', 'rb') as scaler_file_in:\n",
    "        with gzip.open('standard_scaler.pkl.gz', 'wb') as scaler_file_out:\n",
    "            scaler_file_out.write(scaler_file_in.read())  # Properly write the binary contents to gzip\n",
    "\n",
    "\n",
    "    # Train the Random Forest model\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f'Mean Squared Error: {mse}')\n",
    "    print(f'R-squared: {r2}')\n",
    "\n",
    "    # Feature importance\n",
    "    feature_importance = model.feature_importances_\n",
    "    feature_importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importance})\n",
    "    print(feature_importance_df)\n",
    "    # Save the random forest model in binary\n",
    "    with open('random_forest_risk_score_model.pkl', 'wb') as model_file_out:\n",
    "        pickle.dump(model, model_file_out)\n",
    "    # Save the random forest model in binary\n",
    "    with open('random_forest_risk_score_model.pkl', 'rb') as model_file_in:\n",
    "        with gzip.open('random_forest_risk_score_model_compressed.pkl.gz', 'wb') as model_file_out:\n",
    "            model_file_out.write(model_file_in.read())  # Properly write the binary contents to gzip\n",
    "else:\n",
    "    print(\"Cannot train the model due to missing features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White, Good Health: Predicted Risk Score = 1.8827092787174313\n",
      "Black, Good Health: Predicted Risk Score = 4.359724952208392\n",
      "White, Bad Health: Predicted Risk Score = 6.941566162731443\n",
      "Black, Bad Health: Predicted Risk Score = 6.116463232141847\n"
     ]
    }
   ],
   "source": [
    "# 1. White, Good Health\n",
    "white_good_health = pd.DataFrame({\n",
    "    'cost_t': [1000],      # Low cost\n",
    "    'age': [30],           # Younger age\n",
    "    'dem_female': [0],     # Male\n",
    "    'race': [0],           # White\n",
    "    'biomarkers': [1],     # Normal biomarkers\n",
    "    'comorbidity': [1]     # Low comorbidity\n",
    "})\n",
    "\n",
    "# 2. Black, Good Health\n",
    "black_good_health = pd.DataFrame({\n",
    "    'cost_t': [1200],      # Low cost\n",
    "    'age': [35],           # Younger age\n",
    "    'dem_female': [1],     # Female\n",
    "    'race': [1],           # Black\n",
    "    'biomarkers': [1],     # Normal biomarkers\n",
    "    'comorbidity': [2]     # Low comorbidity\n",
    "})\n",
    "\n",
    "# 3. White, Bad Health\n",
    "white_bad_health = pd.DataFrame({\n",
    "    'cost_t': [4000],      # High cost\n",
    "    'age': [60],           # Older age\n",
    "    'dem_female': [1],     # Female\n",
    "    'race': [0],           # White\n",
    "    'biomarkers': [0],     # Abnormal biomarkers\n",
    "    'comorbidity': [4]     # High comorbidity\n",
    "})\n",
    "\n",
    "# 4. Black, Bad Health\n",
    "black_bad_health = pd.DataFrame({\n",
    "    'cost_t': [4500],      # High cost\n",
    "    'age': [55],           # Older age\n",
    "    'dem_female': [0],     # Male\n",
    "    'race': [1],           # Black\n",
    "    'biomarkers': [0],     # Abnormal biomarkers\n",
    "    'comorbidity': [3]     # High comorbidity\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "# Decompress and load the saved random forest model\n",
    "with gzip.open('random_forest_risk_score_model_compressed.pkl.gz', 'rb') as model_file_in:\n",
    "    model = pickle.load(model_file_in)\n",
    "\n",
    "# Decompress and load the saved scaler\n",
    "with gzip.open('standard_scaler.pkl.gz', 'rb') as scaler_file_in:\n",
    "    scaler = pickle.load(scaler_file_in)\n",
    "\n",
    "# Define the features used for prediction\n",
    "features = ['cost_t', 'age', 'dem_female', 'race', 'biomarkers', 'comorbidity']\n",
    "\n",
    "# Make prediction for each dummy data entry separately\n",
    "\n",
    "# 1. White, Good Health\n",
    "if all(feature in white_good_health.columns for feature in features):\n",
    "    X_white_good_health = white_good_health[features]\n",
    "    X_white_good_health = scaler.transform(X_white_good_health)\n",
    "    predicted_risk_score_white_good_health = model.predict(X_white_good_health)[0]\n",
    "    print(f\"White, Good Health: Predicted Risk Score = {predicted_risk_score_white_good_health}\")\n",
    "else:\n",
    "    print(\"White, Good Health: Missing required features\")\n",
    "\n",
    "# 2. Black, Good Health\n",
    "if all(feature in black_good_health.columns for feature in features):\n",
    "    X_black_good_health = black_good_health[features]\n",
    "    X_black_good_health = scaler.transform(X_black_good_health)\n",
    "    predicted_risk_score_black_good_health = model.predict(X_black_good_health)[0]\n",
    "    print(f\"Black, Good Health: Predicted Risk Score = {predicted_risk_score_black_good_health}\")\n",
    "else:\n",
    "    print(\"Black, Good Health: Missing required features\")\n",
    "\n",
    "# 3. White, Bad Health\n",
    "if all(feature in white_bad_health.columns for feature in features):\n",
    "    X_white_bad_health = white_bad_health[features]\n",
    "    X_white_bad_health = scaler.transform(X_white_bad_health)\n",
    "    predicted_risk_score_white_bad_health = model.predict(X_white_bad_health)[0]\n",
    "    print(f\"White, Bad Health: Predicted Risk Score = {predicted_risk_score_white_bad_health}\")\n",
    "else:\n",
    "    print(\"White, Bad Health: Missing required features\")\n",
    "\n",
    "# 4. Black, Bad Health\n",
    "if all(feature in black_bad_health.columns for feature in features):\n",
    "    X_black_bad_health = black_bad_health[features]\n",
    "    X_black_bad_health = scaler.transform(X_black_bad_health)\n",
    "    predicted_risk_score_black_bad_health = model.predict(X_black_bad_health)[0]\n",
    "    print(f\"Black, Bad Health: Predicted Risk Score = {predicted_risk_score_black_bad_health}\")\n",
    "else:\n",
    "    print(\"Black, Bad Health: Missing required features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Risk Score: 0.0\n",
      "Maximum Risk Score: 100.0\n",
      "count    48784.000000\n",
      "mean         4.393692\n",
      "std          5.519582\n",
      "min          0.000000\n",
      "25%          1.443859\n",
      "50%          2.887719\n",
      "75%          5.350773\n",
      "max        100.000000\n",
      "Name: risk_score_t, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df' is your DataFrame and 'risk_score_t' is the column with the risk scores\n",
    "min_risk_score = df['risk_score_t'].min()\n",
    "max_risk_score = df['risk_score_t'].max()\n",
    "\n",
    "print(f\"Minimum Risk Score: {min_risk_score}\")\n",
    "print(f\"Maximum Risk Score: {max_risk_score}\")\n",
    "\n",
    "# Statistical summary of the 'risk_score_t' column\n",
    "risk_score_description = df['risk_score_t'].describe()\n",
    "print(risk_score_description)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
