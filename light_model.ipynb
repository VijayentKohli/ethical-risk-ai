{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- risk_score_t ---\n",
      "Mean Squared Error: 19.052080359758705\n",
      "R-squared: 0.32714601843142577\n",
      "Coefficients for 'risk_score_t':\n",
      "                 Feature  Coefficient\n",
      "4            comorbidity     1.096917\n",
      "10         hct_tests_tm1     1.027510\n",
      "0                    age     0.830940\n",
      "12      nt_bnp_tests_tm1     0.569897\n",
      "6          cre_tests_tm1     0.480123\n",
      "13      sodium_tests_tm1     0.467044\n",
      "8          esr_tests_tm1     0.453609\n",
      "9       ghba1c_tests_tm1     0.419449\n",
      "14        trig_tests_tm1    -0.352903\n",
      "5   lasix_dose_count_tm1     0.325556\n",
      "3             biomarkers    -0.176155\n",
      "11         ldl_tests_tm1     0.036626\n",
      "2                   race    -0.015352\n",
      "7          crp_tests_tm1     0.009187\n",
      "1             dem_female     0.000409\n",
      "\n",
      "\n",
      "--- cost_t ---\n",
      "Mean Squared Error: 291989351.3257087\n",
      "R-squared: 0.09701699405394748\n",
      "Coefficients for 'cost_t':\n",
      "                 Feature  Coefficient\n",
      "10         hct_tests_tm1  2908.027564\n",
      "6          cre_tests_tm1  2580.747284\n",
      "13      sodium_tests_tm1 -1793.881620\n",
      "8          esr_tests_tm1  1461.873988\n",
      "14        trig_tests_tm1 -1396.589156\n",
      "4            comorbidity  1351.443871\n",
      "5   lasix_dose_count_tm1  1020.215806\n",
      "9       ghba1c_tests_tm1   908.932156\n",
      "12      nt_bnp_tests_tm1   901.344735\n",
      "11         ldl_tests_tm1   769.537691\n",
      "1             dem_female   555.164351\n",
      "3             biomarkers  -357.898403\n",
      "0                    age   325.952903\n",
      "2                   race    75.002249\n",
      "7          crp_tests_tm1    34.930428\n",
      "\n",
      "\n",
      "--- bps_mean_t ---\n",
      "Mean Squared Error: 314.7446432979357\n",
      "R-squared: 0.05544539583356656\n",
      "Coefficients for 'bps_mean_t':\n",
      "                 Feature  Coefficient\n",
      "4            comorbidity     2.265383\n",
      "0                    age     1.653530\n",
      "13      sodium_tests_tm1     1.301333\n",
      "1             dem_female    -1.069043\n",
      "2                   race    -0.816921\n",
      "9       ghba1c_tests_tm1     0.775470\n",
      "10         hct_tests_tm1    -0.742511\n",
      "6          cre_tests_tm1    -0.286345\n",
      "12      nt_bnp_tests_tm1    -0.198931\n",
      "8          esr_tests_tm1    -0.156422\n",
      "3             biomarkers     0.153251\n",
      "5   lasix_dose_count_tm1     0.125730\n",
      "14        trig_tests_tm1    -0.100947\n",
      "11         ldl_tests_tm1     0.075531\n",
      "7          crp_tests_tm1     0.034451\n",
      "\n",
      "\n",
      "--- gagne_sum_t ---\n",
      "Mean Squared Error: 1.976598823795759\n",
      "R-squared: 0.46814782453994497\n",
      "Coefficients for 'gagne_sum_t':\n",
      "                 Feature  Coefficient\n",
      "4            comorbidity     0.787672\n",
      "9       ghba1c_tests_tm1     0.349591\n",
      "6          cre_tests_tm1     0.225201\n",
      "0                    age     0.210093\n",
      "12      nt_bnp_tests_tm1     0.195638\n",
      "10         hct_tests_tm1     0.122179\n",
      "13      sodium_tests_tm1     0.105144\n",
      "5   lasix_dose_count_tm1     0.092015\n",
      "8          esr_tests_tm1     0.088840\n",
      "14        trig_tests_tm1    -0.087212\n",
      "2                   race    -0.081011\n",
      "3             biomarkers    -0.033475\n",
      "7          crp_tests_tm1     0.027691\n",
      "11         ldl_tests_tm1     0.020606\n",
      "1             dem_female    -0.016923\n",
      "\n",
      "\n",
      "--- ldl_mean_t ---\n",
      "Mean Squared Error: 425.5906961285202\n",
      "R-squared: 0.01602772340059644\n",
      "Coefficients for 'ldl_mean_t':\n",
      "                 Feature  Coefficient\n",
      "6          cre_tests_tm1    -1.962671\n",
      "9       ghba1c_tests_tm1    -1.846333\n",
      "13      sodium_tests_tm1     1.620988\n",
      "11         ldl_tests_tm1     1.523749\n",
      "4            comorbidity    -1.028968\n",
      "0                    age    -0.933914\n",
      "1             dem_female     0.718979\n",
      "14        trig_tests_tm1    -0.621511\n",
      "8          esr_tests_tm1     0.477902\n",
      "2                   race    -0.407464\n",
      "7          crp_tests_tm1     0.200780\n",
      "10         hct_tests_tm1    -0.160267\n",
      "3             biomarkers     0.080575\n",
      "12      nt_bnp_tests_tm1     0.066264\n",
      "5   lasix_dose_count_tm1     0.011460\n",
      "\n",
      "\n",
      "Model training and evaluation completed successfully.\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import gzip\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "data_path = 'data_new.csv'\n",
    "if not os.path.exists(data_path):\n",
    "    raise FileNotFoundError(f\"The data file {data_path} does not exist.\")\n",
    "df = pd.read_csv(data_path)\n",
    "df.head()\n",
    "\n",
    "# Define age band columns and their corresponding numerical values\n",
    "age_band_columns = [\n",
    "    'dem_age_band_18-24_tm1', 'dem_age_band_25-34_tm1', 'dem_age_band_35-44_tm1',\n",
    "    'dem_age_band_45-54_tm1', 'dem_age_band_55-64_tm1', 'dem_age_band_65-74_tm1', 'dem_age_band_75+_tm1'\n",
    "]\n",
    "age_mapping = {\n",
    "    'dem_age_band_18-24_tm1': 21,\n",
    "    'dem_age_band_25-34_tm1': 30,\n",
    "    'dem_age_band_35-44_tm1': 40,\n",
    "    'dem_age_band_45-54_tm1': 50,\n",
    "    'dem_age_band_55-64_tm1': 60,\n",
    "    'dem_age_band_65-74_tm1': 70,\n",
    "    'dem_age_band_75+_tm1': 80\n",
    "}\n",
    "df['age'] = 0\n",
    "for band, age_val in age_mapping.items():\n",
    "    if band in df.columns:\n",
    "        df['age'] += df[band] * age_val\n",
    "\n",
    "# Handle missing values by filling with median for numeric columns\n",
    "df.fillna(df.median(numeric_only=True), inplace=True)\n",
    "\n",
    "# Encode the categorical variable 'race' if necessary\n",
    "if 'race' in df.columns and df['race'].dtype == 'object':\n",
    "    df['race'] = LabelEncoder().fit_transform(df['race'])\n",
    "\n",
    "# Define biomarker columns and create a consolidated 'biomarkers' feature\n",
    "biomarker_columns = [\n",
    "    'cre_min-low_tm1', 'cre_min-high_tm1', 'cre_min-normal_tm1',\n",
    "    'cre_mean-low_tm1', 'cre_mean-high_tm1', 'cre_mean-normal_tm1',\n",
    "    'cre_max-low_tm1', 'cre_max-high_tm1', 'cre_max-normal_tm1',\n",
    "    'crp_min-low_tm1', 'crp_min-high_tm1', 'crp_min-normal_tm1',\n",
    "    'crp_mean-low_tm1', 'crp_mean-high_tm1', 'crp_mean-normal_tm1',\n",
    "    'crp_max-low_tm1', 'crp_max-high_tm1', 'crp_max-normal_tm1'\n",
    "    # ... (add additional biomarker columns as needed)\n",
    "]\n",
    "non_empty_biomarker_columns = df[biomarker_columns].dropna(axis=1, how='all')\n",
    "if len(non_empty_biomarker_columns.columns) < 10:\n",
    "    random_10_biomarker_columns = non_empty_biomarker_columns.columns.tolist()\n",
    "    print(f\"Only {len(random_10_biomarker_columns)} biomarker columns available. Using all.\")\n",
    "else:\n",
    "    random_10_biomarker_columns = non_empty_biomarker_columns.sample(n=10, axis=1, random_state=42).columns.tolist()\n",
    "valid_biomarker_columns = [col for col in random_10_biomarker_columns if col in df.columns]\n",
    "if valid_biomarker_columns:\n",
    "    df['biomarkers'] = df[valid_biomarker_columns].apply(\n",
    "        lambda row: 1 if any('normal' in col and row[col] > 0 for col in valid_biomarker_columns) else 0,\n",
    "        axis=1\n",
    "    )\n",
    "else:\n",
    "    df['biomarkers'] = 0\n",
    "    print(\"No valid biomarker columns found. Setting 'biomarkers' to 0.\")\n",
    "\n",
    "# Define comorbidity columns and create a consolidated 'comorbidity' feature\n",
    "comorbidity_columns = [\n",
    "    'alcohol_elixhauser_tm1', 'anemia_elixhauser_tm1', 'arrhythmia_elixhauser_tm1',\n",
    "    'arthritis_elixhauser_tm1', 'bloodlossanemia_elixhauser_tm1', 'coagulopathy_elixhauser_tm1',\n",
    "    'compdiabetes_elixhauser_tm1', 'depression_elixhauser_tm1', 'drugabuse_elixhauser_tm1',\n",
    "    'electrolytes_elixhauser_tm1', 'hypertension_elixhauser_tm1'\n",
    "    # ... (add additional comorbidity columns as needed)\n",
    "]\n",
    "non_empty_comorbidity_columns = df[comorbidity_columns].dropna(axis=1, how='all')\n",
    "if len(non_empty_comorbidity_columns.columns) < 10:\n",
    "    random_10_comorbidity_columns = non_empty_comorbidity_columns.columns.tolist()\n",
    "    print(f\"Only {len(random_10_comorbidity_columns)} comorbidity columns available. Using all.\")\n",
    "else:\n",
    "    random_10_comorbidity_columns = non_empty_comorbidity_columns.sample(n=10, axis=1, random_state=42).columns.tolist()\n",
    "valid_comorbidity_columns = [col for col in random_10_comorbidity_columns if col in df.columns]\n",
    "if valid_comorbidity_columns:\n",
    "    df['comorbidity'] = df[valid_comorbidity_columns].apply(\n",
    "        lambda row: 1 if any(row[col] > 0 for col in valid_comorbidity_columns) else 0,\n",
    "        axis=1\n",
    "    )\n",
    "else:\n",
    "    df['comorbidity'] = 0\n",
    "    print(\"No valid comorbidity columns found. Setting 'comorbidity' to 0.\")\n",
    "\n",
    "# Define features and targets\n",
    "features = [\n",
    "    'age', 'dem_female', 'race', 'biomarkers', 'comorbidity',\n",
    "    'lasix_dose_count_tm1', 'cre_tests_tm1', 'crp_tests_tm1', 'esr_tests_tm1',\n",
    "    'ghba1c_tests_tm1', 'hct_tests_tm1', 'ldl_tests_tm1', 'nt_bnp_tests_tm1',\n",
    "    'sodium_tests_tm1', 'trig_tests_tm1'\n",
    "]\n",
    "missing_features = [f for f in features if f not in df.columns]\n",
    "if missing_features:\n",
    "    print(f\"Missing features from dataset: {missing_features}\")\n",
    "\n",
    "target_columns = ['risk_score_t', 'cost_t', 'bps_mean_t', 'gagne_sum_t', 'ldl_mean_t']\n",
    "missing_targets = [t for t in target_columns if t not in df.columns]\n",
    "if missing_targets:\n",
    "    raise KeyError(f\"Missing target columns: {missing_targets}\")\n",
    "\n",
    "# Prepare training and testing sets\n",
    "if not missing_features and not missing_targets:\n",
    "    X = df[features]\n",
    "    y = df[target_columns]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Save and compress the scaler\n",
    "    with open('standard_scaler.pkl', 'wb') as f:\n",
    "        pickle.dump(scaler, f)\n",
    "    with open('standard_scaler.pkl', 'rb') as fin, gzip.open('standard_scaler.pkl.gz', 'wb') as fout:\n",
    "        fout.write(fin.read())\n",
    "\n",
    "    # Use a lightweight linear model for multi-output regression\n",
    "    model = MultiOutputRegressor(LinearRegression())\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    for idx, target in enumerate(target_columns):\n",
    "        mse = mean_squared_error(y_test.iloc[:, idx], y_pred[:, idx])\n",
    "        r2 = r2_score(y_test.iloc[:, idx], y_pred[:, idx])\n",
    "        print(f\"--- {target} ---\")\n",
    "        print(f\"Mean Squared Error: {mse}\")\n",
    "        print(f\"R-squared: {r2}\")\n",
    "        # For linear regression, coefficients can serve as a proxy for feature importance\n",
    "        coefficients = model.estimators_[idx].coef_\n",
    "        coef_df = pd.DataFrame({\n",
    "            'Feature': features,\n",
    "            'Coefficient': coefficients\n",
    "        }).sort_values(by='Coefficient', key=abs, ascending=False)\n",
    "        print(f\"Coefficients for '{target}':\")\n",
    "        print(coef_df)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    # Save and compress the model\n",
    "    with open('multi_output_linear_model.pkl', 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    with open('multi_output_linear_model.pkl', 'rb') as fin, gzip.open('multi_output_linear_model_compressed.pkl.gz', 'wb') as fout:\n",
    "        fout.write(fin.read())\n",
    "    print(\"Model training and evaluation completed successfully.\")\n",
    "else:\n",
    "    print(\"Cannot proceed with model training due to missing features or target columns.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
